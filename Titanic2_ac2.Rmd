---
title: "Titanic2"
author: "Aleix Cortina, Kilian Cañizares"
date: "5/8/2020"
output:
  html_document:
    toc :  yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
# set working directory where this file is located
setwd("./")
```


## 1. Descripción del Dataset

En esta práctica se va a analizar el juego de datos del Titanic que se puede encontrar en:  

https://www.kaggle.com/c/titanic  

y cuyos datos se encuentran en el fichero "train.csv". 

Este es un conjunto de datos referente a los pasajeros del Titanic que se compone de un total de 12 variables que a continuación se describen: 

- **PassagerId**: Identifica a cada pasejero por un identificador. Formato entero.   
- **Survived**: Especifica si un pasajero sobrevivió (1) o no (0). Formato entero.  
- **Pclass**: Indica la clase en que un pasajero viajaba. Formato entero. 
- **Name**: Nombre del pasajero. Formato factor. 
- **Sex**: Sexo del pasajero. Formato factor.  
- **Age**: Edad del pasajero en años. Formato numérico. 
- **SibSp**: Número de familiares o cónyugues a bordo. Formato entero.  
- **Parch**: Número padres e hijos a bordo. Formato entero. 
- **Ticket**. Número de ticket del pasajero. Formato factor. 
- **Fare**: Precio del ticket en dolares. Formato numérico. 
- **Cabin**: Número de cabina del pasajero. Formato factor.  
- **Embarked**: Lugar de embarque del pasajero. Formato factor. 
 
Con un número total de observaciones de 891.  

El objetivo de la creación de este conjunto de datos, es analizar si existe una relación entre la probabilidad de supervicencia de un pasajero, y el resto de variables del conjunto de datos. Si bien el hecho de predecir la supervicencia en el naufragio del Titanic no es relevante en la actuaidad, las mejoras derivadas del entrenamiento de este tipo de algoritmos pueden tener aplicaciones importantes en áreas como la salud (i.e. predecir la mortalidad en función de hábitos y variables físicas del paciente), seguros (i.e. predecir el valor de un seguro en función de las características de un cliente), entre otras.  

## 2.Integración y selección de los datos de interés a analizar

```{r carga de datos}
# Carga del juego de datos
datos<-read.csv("train.csv", sep = ",", header = TRUE)

# Estructura de los datos
str(datos)
# Descipción de los datos
summary(datos)
```

Como se puede observar, existen dos variables que tienen un valor único para cada observación: **PassengerId** y **Name**. Estas variables no se tendrán en cuenta en el análisis ya que no dan información diferencial para calcular la probabilidad de que un pasejero sobreviva o no. Por el momento se mantienen estas variables ya que pueden ser de ayuda para algún tratamiento de datos, pero para no sobreespecializar el algoritmo a nivel de la identidad de los pasajeros (nos interesa entender el comportamiento de las variables más genéricas) no se tendrán en cuenta para el análisis y se procederá con su eliminación antes de comenzar los análisis.

El resto de variables, serán usadas para comprender la probabilidad de supervivencia. En primer lugar, se discretizarán las variables **Pclass** referente a la clase dodne viajó el pasajero, y **Survived** que se refiere a si sobrevivió o no, ya que ambas a pesar de estar en formato *int* se consideran categóricas.

```{r datos que entran en el análisis }
# Discretización de variables.
datos$Survived<-as.factor(datos$Survived)
datos$Pclass<-as.factor(datos$Pclass)
```

## 3. Limpieza de datos

Es este apartado, además de limpiar los datos, se van a efectuar transformaciones en las variables para optimizar su uso en el análisis.

### 3.1. Ceros, elementos vacios y NA
Para evaluar la presencia de NA,  elementos vacíos o ceros,  se ejecutan las siguientes rutinas 
```{r ceros o elementos vacios }
# Presencia de valores NA
colSums(is.na(datos))

# Presencia de valores vacíos
colSums(datos=="")

# Presencia de valores 0
colSums(datos==0)
```

La variable **Age** contiene un total de 177 valores NA. Además, las variables **Cabin** y **Embarked** tienen un total de 687 y 2  valores vacios respectivamente. Por otro lado, los ceros pueden ser un valor aceptable en variables como **Survived** indicando que el pasajero no sobrevivió, en **SibSp** indicando el número de familiares o cónyugues, o en **Parch** indicando el número de padres e hijos. Sin embargo, los 15 valores 0 de la variable **Fare** carecen de sentido, así que serán tratados como valores pérdidos. 

#### 3.1.1. Valores vacíos y 0
Las variables a tratar en este apartado son **Fare**, **Cabin** y **Embarked**. 
Respecto a la variable **Cabin**, proporciona información de la cabina donde se alojó un pasajero. Los valores vacíos corresponden a pasajeros que no se han alojado en cabina. El hecho que esté alojado en cabina debería de estar relacionado con la clase en al que se aloja el pasajero, y por lo tanto seguramente con la probabilidad de supervivencia. Primero se comprobará mediante un test *Chi-cuadrado* si existe o no dependencia entre tener asigando un número de cabina y la supervicencia mediante el siguiente test de hipótesis: 

$$
\text{Hipótesis nula. } H_0 \text{: Las variables son independientes.}
\\
\text{Hipótesis alternativa. } H_1 \text{: Las variables  no son independientes.}
$$


```{r variable Cabin, message = FALSE }

library(plyr)
# Discretización variable Cabin

cabin_cat <- as.factor(
  sapply(datos$Cabin, function (cabin) if (cabin=="") "without_cabin" else "with_cabin")
  )

chisq.test(datos$Survived, cabin_cat)
```
 
Como se puede observar la $p < \alpha = 0.05$ y se puede concluir que las variables no son independientes, luego existe una relación entre la supervivencia y el hecho de tener asignada una cabina. Así que se categorizará esta variable con dos niveles: *with_cabin* y *without_cabin* y se usará para el análisis.

```{r generar la variable cabin cat}
# Se crea la nueva varibale Cabin
datos$Cabin<-cabin_cat

# eliminamos la variable utilizada del entorno de trabajo
remove(cabin_cat)
```

Respecto a la variable **Fare**, existen 15 valores cuyo valor es 0, debido al bajo número de valores faltantes, se procederá a la imputación de datos a partir del método de los vecinos más próximos mediante la función `kNN()`. Se considera que las variables que pueden tener relación con el valor del billete son: Clase del billete (**Pclass**), si es o no de cabina (**Cabin**) y el lugar de embarque (**Embarked**). La variable **Embarked** tiene dos valores vacíos, pero ninguno de ellos coincide con los valores que queremos imputar.

```{r imputacion Fare, message = FALSE}
library(VIM)
# Se crea el datFrame para imputar los valores
datos_a_usar <- subset(datos,
                       select = c("Pclass", "Embarked", "Cabin" ,"Fare"))

# Se pasan a NA los valores que queremos imputar
index_imputados_fare <- which(datos$Fare==0)
datos_a_usar$Fare[index_imputados_fare] <- NA

# Se escojen 3 vecinos más proximos
datos_imputados<-kNN(datos_a_usar,k=3)

# Se muestran los datos imputados
datos_imputados$Fare[index_imputados_fare]

# Se pasan al dataFrame original
datos$Fare <- datos_imputados$Fare

# eliminamos los conjuntos de datos que no vamos a usar más
remove(datos_a_usar, datos_imputados, index_imputados_fare)
```

La variable **Embarked** tiene 3 niveles diferentes, e informa del puerto en que embarcó el pasajero. Contiene dos valores vacios que al igual que en el caso de **Fare** serán imputados. Para esta imputación se usarán también las variables **Fare**, **Pclass** y **Cabin**, ya que se considera que hay una relación entre precio, si es cabina o no, la clase  y la puerta de embarque.

```{r variable Embarked imputacion, message = FALSE }
library(gdata)
# Se crea el datFrame para imputar los valores 
datos_a_usar <- subset(datos,
                       select = c("Pclass", "Embarked", "Cabin" ,"Fare"))

# Se pasan a NA los valores que queremos imputar
index_imputados_embarked<-which(datos$Embarked=="")
datos_a_usar$Embarked[index_imputados_embarked]<-NA

# Se escojen 3 vecinos más proximos
datos_imputados<-kNN(datos_a_usar,k=3)

# Se muestran los datos imputados
datos_imputados$Embarked[index_imputados_embarked]

# Se pasan al dataFrame original y se eliminan los niveles que ya no se usan (i.e. "")
datos$Embarked<-datos_imputados$Embarked
datos$Embarked<-drop.levels(datos$Embarked)

# eliminamos las variables no usadas posteriormente
remove(datos_a_usar, datos_imputados, index_imputados_embarked)
```

#### 3.1.2. Valores NA

Esta presenta un total de 177 valores NA que se han de estudiar para  tomar una decisión a cerca de su tratamiento. Debido al gran numero con respecto al total (177 sobre 891) no se considera una buena opción eliminar los casos. Por lo tanto, primero se evaluará si dichos valores (nulos) tienen una relación con el hecho que el indidividuo sobreviva o no. Anterioremente, se ha visto que la clase determina en cierto modo las proabibilidades de sobrevivir o no, y posiblemente el hecho de disponer o no de la edad puede depender de la clase. Para ver si hay o no dependencia entre **Survived** y **Age** primero se categorizará la variable **Age** en función de si se especifica o no la edad, para posteriomente hacer un test *Chi-cuadrado* de dependencia de variables mediante la función `chisq.test()` donde se contrastan las siguiente hipótesis:

$$
\text{Hipótesis nula. } H_0 \text{: Las variables son independientes.}
\\
\text{Hipótesis alternativa. } H_1 \text{: Las variables  no son independientes.}
$$
```{r variable Age valores no presentes, message = FALSE }

edad_presente <- sapply(datos$Age, function (age) if (is.na(age)) "edad_no_especificada" else "edad_especificada")

# Creación de tabla de contingencia 
table_prop<-table(edad_presente,datos$Survived)
# Test Chi cuadrado
chisq.test(table_prop)

# eliminamos variables no usadas posteriormente
remove(edad_presente, table_prop)
```

Como se puede observar el $\text{p-valor} < \alpha=0.05$, donde $\alpha = 0.05$ es el nivel de significación para un nivel de confianza del 95%, por lo tanto, rechazamos $H_0$  concluyendo que las variables son dependientes, luego existe una relación entre haber proporcionado la edad y la supervivencia.  

Por ello, no se recomienda hacer ningún cálculo como puede ser la media para completar esta variable ya que le estariamos dando un valor promedio no beneficiandonos de su posible poder de predicción para el análisis e introducir error. Una posible solución es imputar los valores por medios probabilísticos a partir de la función `knn()`, y que los casos más cercanos en cuanto a otros atributos determinen el valor. Sin embargo, el gran número de casos de esta variable puede hacer que su gran numero de predicciones (177 sobre 891) la haga poco realista. Se optará por discretizar la variable en función de grupos de edad, y crear un grupo con estas valores con la etiqueta *age_not_specified*.  Para ello se ve si existe primero alguna relación entre edad y supervivencia, para posteriomente crear los grupos.

```{r variable Age distribución }
library(ggplot2)

age_survived_with_specified_age <- subset(
  datos[!is.na(datos$Age), ],
  select = c(Age, Survived)
)

# Grafico de conteos totales en
ggplot(data = age_survived_with_specified_age,
       aes(x=Age,  fill=Survived)
       )+geom_histogram(bins = 80)+ylab("Counts")+xlab("Age")

```
En el histograma de la variable **age** junto con la probabilidad de supervivencia es posible observar que a menos edad mayor tasa de supervivencia. Por lo tanto, nos encontramos ante un escenario dónde sabemos que la edad no especificada es dependiente con la variable **Survived**. Además, pertenecer al rango de menos edad significa tener más probabilidad de sobrevivir. Por lo tanto, para discretizar la variable se ha de escoger un valor óptimo que discretice la edad en grupos maximizando la información sobre la supervivencia o no del pasajero. Para ello se usará los *Odds-Ratio*, que nos medirá si es más probable sobrevivir a una edad con respecto al resto. Para ello se van a escoger edades entre 1 y 30 como humbral de discrimanción y se va a hacer un gráfico con el resultado. 

```{r variable Age odds ratop de supervivencia}
survived_age<-relevel(age_survived_with_specified_age$Survived,ref="1")
result<-double(30)
for (i in 1:30){

  age_th <- as.factor(sapply(age_survived_with_specified_age$Age, 
                   function (age) if (age>i) 0 else 1))
    
  age_th<-as.factor(age_th)
  age_th<-relevel(age_th,ref="1")
  tabla<-table(age_th,survived_age)

  or<-(tabla[1]*tabla[4])/(tabla[2]*tabla[3])
  result[i]<-or
}
plot(result, xlab ="Age", ylab="Odds-Ratio", yaxp  = c(0, 10, 10))
```

Como se puede observar, a medida que disminuye la edad aumenta la probabilidad de supervivencia, la cual se mantiene al doble para edades menores de 16 años. A partir de 21, se puede considerar que la edad no es significativa siendo la *Odds-ratio* similiar a 1. Escoger una edad muy baja, mejora la predicción , sin embargo,  como se ve en el histograma, la mayoria de la poblacion esta concentrada en edades alrededor de 30 años. Por lo tanto,  esta variable dejará de ser util para un segmento amplio de nuestro juego de datos. Escoger un valor muy alto de edad, puede hacer la variable mas útil para una mayor parte del juego de datos pero con menor capacidad predictiva. Por ello se escogera un valor de compromiso, considerando como que el doble de probabilidad de supervivencia es un buen indicador y además incluye a un amplio segmento de la población joven, por lo que para discretizar la variable se usará 16 años como limite entre niño y adulto. Teniendo en cuenta esto, la variable **Age** se discretizará de la siguiente manera para maximizar la información entre los grupos.  

```{r discretización variable age}
## Grupos niño, adulto y sin especificar
categorizar_edad <- function(age) {
  if (is.na(age)) {
    "no_age"
  }
  else if (age <= 16){
    "child"
  }
  else {
    "adult"
  }
}

datos$Age<-as.factor(mapply(categorizar_edad, 
                            age=datos$Age))

```

### 3.2. Identificación y tratamiento de valores extremos. 

El análisis de los valores extremos, se va a efectuar sobre las variables continuas que son: **Fare**, **SibSp** y **Parch**. 

```{r Fare valores extremos, message = FALSE }
library(DescTools)

boxplot(datos$Fare, col="orange", xlab="Fare")
```

Debido a la naturaleza de la variable **Fare**, predominan los precios bajos y, por lo tanto, sigue una distribución lognormal lo que va a provocar una gran cantidad de valores extremos los cuales están aceptados porque representan tickets más caros debido a las condiciones (cabina, embarque...). Mediante la  transformación de Box Cox se intenta mejorar la normalidad y homocedasticidad, lo que llevará a una menor proporción de valores extremos.

```{r}
x<-datos$Fare
x.norm<- BoxCox(x, lambda = BoxCoxLambda(x))

par(mfrow=c(2,2)) 

qqnorm(x, main="Lognormal") 
qqline(x,col=2)

qqnorm(x.norm, main="Box-Cox")
qqline(x.norm,col=2)

hist(x,main="Lognormal", xlab = "Fare", col="orange") 
hist(x.norm, main="Box-Cox", xlab = "Fare", col="orange")

# Se introducen los datos en el dataFrame

datos$Fare<-x.norm
```
Despues de la transformación, ya no se observa la presencia de *outliers* los cuales habían sido previamente aceptados por la naturalidad de los datos: 

```{r boxplots Fare}
boxplot(datos$Fare, col="orange", xlab="Fare")
```
En el caso de las variables **SibSp** y **Parch**  si realizamos el *boxplot* se observa que presentan muchos valores extremos. Esto es debido a la naturaleza de las variables que se puede visualizar mediante histrogramas y la curva de los cuartiles teoricos vs observados. Como las variables **SibSp** y **Parch** contienen el número de parentescos es común tener predominancia en los núemeros bajos y menos casos a menudo que aumenta el valor de la variable. Aunque son númericas, su distribución es similiar a la de las variable discretas con las observaciones agrupándose en determinados valores (i.e. 0, 1, 2....). Debido a su naturaleza se considera que la discretización de ambas aportará más valor al análisis ya que no es posible normalizar la variable. 

```{r SibSp valores extremos, message = FALSE }
x<-datos$SibSp
y<-datos$Parch

boxplot(x, xlab="SibSp", col = "orange")
boxplot(y, ylab= "Parch", col= "orange")

par(mfrow=c(2,2)) 

qqnorm(x, main="SibSp") 
qqline(x,col=2)

qqnorm(y, main="Parch")
qqline(y,col=2)

hist(x, main="", xlab = "SibSp", col="orange") 
hist(y, main="", xlab = "Parch", col="orange")
```

Si la variable **SibSp** nos indica el número de conyuges o hermanos y la variable **Parch** nos indica el número de padres e hijos debe de haber una relación entre dichas variables.

```{r SibSp y Parch}

SibSp_factor<- as.factor(datos$SibSp)
Parch_factor<- as.factor(datos$Parch)

chisq.test(Parch_factor, SibSp_factor)
```

Teniendo en cuenta que p-valor<0.05,  ambas variables son dependientes. Para no solapar ambas variables en el algoritmo de predicción se crea una nueva variable que contenga el número de parientes la cual será la suma de ambas variables.

```{r creacion variable parents y su dependencia en la supervivencia}
# creamos la nueva variable

datos$Parents <- as.factor(datos$SibSp + datos$Parch)
chisq.test(datos$Parents, datos$Survived)

```

Teniendo en cuenta que el p-valor<0.05 se puede afimar que existe una dependencia entre la nueva variable **Parents** y la supervivencia.Finalmente se eliminan las variables **SibSp** y **Parch** antes de iniciar el análisi de los datos. 


```{r version final de los datos }
datos$SibSp<-NULL
datos$Parch<-NULL
```

## 3.3. Comprobación de la variable Ticket

Se cree que la información de la variable Ticket está implicita en la variable Fare ya que el precio de un Ticket es igual para todos ellos. Se analiza si esto es cierto para no tener en cuenta esta variable en el análisis.

```{r}
# comprobamos si existe alguna diferencia de precio para algún ticket cuyo valor es igual.
tickets_check<-c()
for (i in levels(datos$Ticket)){
 a <- length(unique(datos$Fare[which(datos$Ticket==i)]))
 if(a>1) {
   tickets_check <- append(tickets_check,i)
   }
}
tickets_check

subset(datos[datos$Ticket==tickets_check[1], ], select = c(PassengerId, Ticket, Cabin, Embarked, Fare))
```

Se observa sólo un valor diferente con una variación mínima en la variable Fare. Por lo tanto, consideramos que la información de la variable **Ticket** ya está explicada en la variable **Fare** y, por lo tanto, no es necesaria para el análisis. Además, se considera más conveniente utilizar la variable **Fare** ya que no es identificadora y ayudará más a comprender la supervivencia de los pasajeros. 

```{r}
# eliminamos las variables que no usaremos para el análisis
datos$PassengerId<-NULL
datos$Name<-NULL
datos$Ticket<-NULL
```

Realizamos un `attach` de los datos después de modificar las limpiar las variables para facilitar el uso de ellas en el análisis.

```{r}
attach(datos)
```


# 4. Análisis de los datos

## 4.1. Selección de los grupos de datos que se quieren analizar/comparar (Planificación de los análisis)

En primer lugar, debido a qué el objetivo del análisis es entender qué variables influyen y en qué medida en la supervivencia, se van a realizar contrastes de hipótesis para medir la dependencia de las variables con respecto a la supervivencia. En el caso de las variables categóricas se realizarán test *chi-cuadrado* de la sigueinte manera: 

- **PClass** vs **Survived**
- **Sex** vs **Survived**
- **Age** vs **Survived**
- **Parents** vs **Survived**
- **PClass** vs **Survived**
- **Cabin** vs **Survived**
- **Embarked** vs **Survived**

Además de ver si estas variables son dependientes o no, se va a calcular el estadístico Gamma de Goodman Kruskal que nos da una idea del grado de dependencia de éstas. Los valores estan comprendidos entre -1 y 1, con el signo indicando si la dependencia es positva o negativa y el valor absoluto la fuerza de esta. Los valores cercanos a 0 indican que las dos variables son independientes. 

Por otro lado, en la variable continua **Fare** se hará un contraste de medias respecto a **Survived** con el objetivo de entender si un precio diferente de ticket influye en la probabilidad de supervivencia. 

Una vez comprendida la relación de cada variable con la superviencia, se va a utilizar esta información para saber que variables van a ser usadas en los algoritmos de predicción. En concreto se van a aplicar dos algoritmos supervisados de clasificación para entrenar un nodelo  que nos permita predecir la probabilidad de supervivencia de un pasajero en función de los atributos que disponemos. Estos algoritmos son: 

- Árbol de decisión: Es un algoritmo que va a intentar subdividir el espacio de entrada de datos para generar regiones disjuntas. Cada una de estas regiones estará asociada a los atributos de entrada y tendrá asociada una probabilidad de supervivencia. 

- RandomForests: Es un algoritmo que usa varios clasificadores basados en árboles de decisión para mejorar la predicción. Se construye cada árbol con m predictores escogidos aleatoriamente, y se promedia el conjunto de modelos. 


## 4.2. Comprobación de la normalidad y homogeneidad de la varianza

En el conjunto de datos analizado tan sólo existe una variable numérica, la variable **Fare**. En el apartado 3 se ha tansofrmado la variable para intentar normalizarla ya que esta seguía una distribución lognormal. En primer lugar, se realiza un test de normalidad para entender si se ha conseguido o no normalizar dicha variable.

```{r}
hist(Fare, col = 'darkslategray1',
     main = 'Histograma + densidad de la variable Fare',
     freq = FALSE,
     xlab = 'Fare',
     ylab= "Densidad")
lines(density(Fare), col = 'red', lwd='3')
```
En el gráfico anterior vemos que pese a qué la variable ha sido transformada no sigue una distribución normal. Lo podemos reforzar con un test de normalidad de *saphiro* donde las hipótesis a contrastar son las siguientes:

$$
\text{Hipótesis nula. } H_0 \text{: Sigue una distribución normal}
\\
\text{Hipótesis alternativa. } H_1 \text{: NO sigue una distribución normal}
$$

```{r}
shapiro.test(Fare)
```
Debido a qué $p-valor < \alpha = 0.05$ rechazamos la hipótesis nula y aceptamos que los datos no siguen una distribución normal. Por lo tanto, pese a haber intentado normalizar los datos con una transformación estos no siguen dicha distribución y se tendrá en cuenta para los posteriores análisis de la variable Fare.

Para comprobar la homogeneidad de la variable **Fare** se van a utilizar las variables que se consideran más críticas para definir el precio. Estas son las variables **Embarked**, **Pclass** y **Cabin**. Debido a qué la variable Fare no sigue una distribución normal, nos vemos obligados a realizar un test basado en la mediana. Se va a aplicar el test de Levene ya que este nos permite medir la homocedasticidad o homogeneidad a partir de la mediana sin importar que los datos no signa una distribución normal. Las hipótesis a contrastar en el test es la siguiente:

$$
\text{Hipótesis nula. } H_0 \text{: NO hay diferencias significativas entre las varianzas}
\\
\text{Hipótesis alternativa. } H_1 \text{: Hay diferencias significativas entre las varianzas}
$$

```{r}
# Fare - Embarked
LeveneTest(y = Fare, group = Embarked, center = 'median')

# Fare - Pclass
LeveneTest(y = Fare, group = Pclass, center = 'median')

# Fare - Cabin
LeveneTest(y = Fare, group = Cabin, center = 'median')
```

En los tres resultados del test el $p-valor < \alpha = 0.05$, por lo tanto, rechazamos la hipótesis nula y aceptamos que para todas la variable **Fare** tiene diferencias significativas en términos de varianza para los diferentes factores de las variables **Embarked**, **Pclass** y **Cabin**.

## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. 

### 4.3.1. Dependencia de las variables con respecto a la probabilidad de sobrevivir.

#### 4.3.1.1. Variables categóricas

El test *chi-cuadrado* contrasta las siguientes hipótesis:

$$
\text{Hipótesis nula. } H_0 \text{: Las variables son independientes.}
\\
\text{Hipótesis alternativa. } H_1 \text{: Las variables  no son independientes.}
$$

- **PClass** vs **Survived**
- **Sex** vs **Survived**
- **Age** vs **Survived**
- **Parents** vs **Survived**
- **Cabin** vs **Survived**
- **Embarked** vs **Survived**

```{r}
# Test chi-cuadrado 
chis_test_matrix<-matrix(
                    c(
                      chisq.test(Pclass, Survived)$p.value,
                      chisq.test(Sex, Survived)$p.value,
                      chisq.test(Age, Survived)$p.value,
                      chisq.test(Parents, Survived)$p.value,
                      chisq.test(Cabin, Survived)$p.value,
                      chisq.test(Embarked, Survived)$p.value)
                      ,
                    dimnames = list(c("PClass vs Survived",
                                      "Sex vs Survived",
                                      "Age vs Survived",
                                      "Parents vs Survived",
                                      "Cabin vs Survived",
                                      "Embarked vs Survived")))


chis_test_matrix

# Test Gamma 

datos$Sex<-relevel(datos$Sex, ref="female")
datos$Age<-relevel(datos$Age, ref="child")
datos$Parents <- ordered(datos$Parents, levels = c("3", "2", "1", "6", "0", "4", "5", "7", "10"))

gamma_matrix<-matrix(
                c(
                  GoodmanKruskalGamma(datos$Pclass, y = Survived),
                  GoodmanKruskalGamma(datos$Sex, y = Survived),
                  GoodmanKruskalGamma(datos$Age, y = Survived),
                  GoodmanKruskalGamma(datos$Parents, y = Survived),
                  GoodmanKruskalGamma(datos$Cabin, y = Survived),
                  GoodmanKruskalGamma(datos$Embarked, y = Survived))
                  ,
                dimnames = list(c("PClass vs Survived",
                                  "Sex vs Survived",
                                  "Age vs Survived",
                                  "Parents vs Survived",
                                  "Cabin vs Survived",
                                  "Embarked vs Survived")))

gamma_matrix
```
Para todas las variables el $p-valor < \alpha = 0.05$, luego se rechaza la hipótesis nula a favor de la alternativa. Por lo tanto, todas estas variables son dependientes por lo que todas tienen un peso en la probabilidad de sobrevivir. Además se observa mediante el test Gamma que dicha fuerza es mayor en las variables **Sex**, **Cabin** y **Pclass** y menor en **Parents**, **Embarked** y **Age**. El hecho que el signo sea negativo nos indica que la probabilidad de sobrevivir disminuye a medida que avanzamos en los diferentes niveles del factor y esto depende de como están o han sido reordenados con las funciones *relevel()* o *ordered*. Dicha relación se verá graficamente en el apartado 5 del presente informe, sin embargo, a modo explicativo de las variables que presentan una mayor fuerza en la dependencia decir que el hecho de ser mujer, viajar en cabina y en primera clase aumenta las probabilidades de sobrevivir.  

#### 4.3.1.2. Variables continuas.

El objetivo de este análisis es identificar si existe una relación  entre la media del precio del ticket y la probabilidad de que una persona sobreviva o no. La variable **Fare** no sigue una distribución normal y la varianza es distinta en las poblaciones. Sin embargo, debido a que el número de observaciones es mayor a 30 y en base al Teorema del Límite Central suponemos normalidad. 

Se define el siguiente contraste de hipótesis: 

$$
H_0: \mu_1 = \mu_2
\\
H_1: \mu_1 \neq \mu_2
\\
\text{donde, 1 corresponde al conjunto que sobrevivió y 2 al que no sobrevivió}
$$

En base al Teorema del límite central tenemos la variable $\frac{\overline{X}_1 - \overline{X}_2}{S_{\overline{X}_1 - \overline{X}_2}}$ que sigue una distribución normal $N(0, 1)$.

```{r}
# generamos una función para calcular el estadístico z por el teorema del límite central
calculate_z <- function(x, y) {
  # calculamos el numerador
  z_num <- mean(x) - mean(y)
  z_den <- sqrt(
    ((sd(x)^2)/length(x))
    +
    ((sd(y)^2)/length(y))
  )
  z <- z_num / z_den
  z
}

z <- calculate_z(Fare[Survived==1], Fare[Survived==0])
z;
```

El p-valor asociado a z es:

$$
p = 2P(Z>|z|)
$$

```{r}
2*pnorm(z, lower.tail = F) < 0.05
```

Debido a que el p-valor es inferior al nivel de significancia fijado como $\alpha=0.05$ rechazamos la hipótesis nula a favor de la hipótesis alternativa y podemos considerar que los precios de los tickets de los pasajeros que sobrevivieron son diferentes a los de los pasejeros que no sobrevivieron. Por lo tanto, es una variable que aporta información sobre la probabilidad de supervivencia del pasajero.

### 4.3.2. Algoritmos de clasificación 

#### 4.3.2.1 Árbol de decisión

Es interesante aplicar un árbol de decisión para entender que variables son más significativas a la hora de predecir o no si un pasajero sobrevive.

```{r results='hide'}
library(rpart)
library(rpart.plot)
library(caret)
```
En primer lugar, preparamos los datos. Se decide utilizar como entrenamiento un 80 % de los registros y testear con un 20 %. Se ha decidido esta relación porque es interesante utilizar bastantes registros para entrenar el modelo ya que el objetivo es entender como las variables condicionan a la supervivenvia de los pasajeros. Por lo tanto, nos interesa tener bastantes registros para construir la lógica del modelo.

```{r}
# Selección variable clase y variables predictoras
y_variable<-subset(datos, select = Survived)
x_variables <-subset(datos, select = c(Pclass, Sex, Age, Fare, Cabin, Embarked, Parents))

# Seleccion de los indices para los datos de entrenamiento y test
set.seed(333, sample.kind = "Rounding")
train_index <- sample(1:nrow(x_variables), 0.8 * nrow(x_variables))
test_index <- setdiff(1:nrow(x_variables), train_index)

# Construyendo conjunto de entrenamiento y test 
X_train <- x_variables[train_index,]
y_train <- y_variable[train_index,]

X_test <- x_variables[test_index, ]
y_test <- y_variable[test_index, ]

```

Generamos el árbol de decisión utilizando todas las variables y dibujamos el árbol.

```{r}
# generamos el árbol de decisión
arbol_1 <- rpart(formula = y_train ~ ., data = X_train)
```

A continuación, se realiza una predicción de los datos de test para analizar la accuracy del árbol de decisión.

```{r}
# predicción
predict_tree <- predict(arbol_1, newdata = X_test, type = "class")
# matriz de confusión
confusionMatrix(predict_tree, y_test)
```
El árbol de decisión ha sido capaz de colocar correctamente un 85.47 % de los registros de test, los cuales corresponden a un 20 % de nuestra población.

### 4.3.2.2 RandomForest

A continuación, aplicamos el algoritmo de Random Forest. Este algoritmo genera diferentes árboles de decisión para clasificar las diferentes variables y decidir si un pasajero sobrevive o no dependiendo de las variables. Se aplica este tipo de algoritmo con dos motivos, por un lado, un random forest es una buena alternativa cuando tenemos muchas variables categóricas de entrad. Por otro lado, nos ayuda a comprender el poder del árbol de decisión generado anteriormente ya que el algoritmo de random forest nos genera muchos árboles con diferentes condiciones.

```{r, results='hide'}
library(randomForest)
# devtools::install_github("MI2DataLab/randomForestExplainer")
library(randomForestExplainer)
```

A continuación, se genera el random forest para predecir la variable **Survived** en relación a todas las demás variables de entrada.

```{r}
rf <- randomForest(
  y_train ~ .,
  data=X_train
)
```

Se realiza una predicción con la parte restante de los datos no utilizada. Se han dividido los datos en un 80/20 % ya que el principal objetivo de este estadístico es ver la capacidad de las variables para explicar si un pasajero sobrevive o no.

```{r}
predict_random_forest = predict(rf, newdata=X_test)
# matriz de confusión
confusionMatrix(predict_random_forest, y_test)
```

Se observa cómo el porcentaje de aciertos así como el intervalo de confianza han disminuido. Por lo tanto, nuestro set de datos se explica (al menos para este orden aleatorio de los datos) peor la superviviencia que el árbol de decisión aplicado anteriormente.

## 5. Representación de los resultados a partir de tablas y gráficas

### 5.1.Dependencia de las variables con respecto a la probabilidad de sobrevivir

En este apartado se va a representar gráficamente la dependencia de las variables categóricas con respecto a la probabilidad de sobrevivir.
```{r }
library(ggpubr)

p1<- ggplot(data=datos, aes(x=Pclass,fill=Survived)) + geom_bar(position="fill") + ylab("Frecuency") + xlab("Pclass") + ggtitle(paste("Gamma = ",toString(round(gamma_matrix[1], digits = 2)))) + theme(plot.title = element_text(size=10,hjust = 0.5))

p2<-ggplot(data=datos, aes(x=Sex,fill=Survived))+geom_bar(position="fill") +xlab("Sex")+theme(axis.title.y=element_blank())+ggtitle(paste("Gamma = ",toString(round(gamma_matrix[2], digits = 2))))+ theme(plot.title = element_text(size=10,hjust = 0.5))

p3<-ggplot(data=datos, aes(x=Age,fill=Survived))+geom_bar(position="fill")+ylab("Frecuency")+xlab("Age")+theme(axis.title.y=element_blank())+ggtitle(paste("Gamma = ",toString(round(gamma_matrix[3], digits = 2))))+ theme(plot.title = element_text(size=10,hjust = 0.5))

p4<-ggplot(data=datos, aes(x=Parents,fill=Survived))+geom_bar(position="fill")+ylab("Frecuency")+xlab("Parents")+ggtitle(paste("Gamma = ",toString(round(gamma_matrix[4], digits = 2))))+ theme(plot.title = element_text(size=10,hjust = 0.5))

p5<-ggplot(data=datos, aes(x=Cabin,fill=Survived))+geom_bar(position="fill")+ylab("Frecuency")+xlab("Cabin")+theme(axis.title.y=element_blank())+ggtitle(paste("Gamma = ",toString(round(gamma_matrix[5], digits = 2))))+ theme(plot.title = element_text(size=10,hjust = 0.5))

p6<-ggplot(data=datos, aes(x=Embarked,fill=Survived))+geom_bar(position="fill")+ylab("Frecuency")+xlab("Embarked")+theme(axis.title.y=element_blank())+ggtitle(paste("Gamma = ",toString(round(gamma_matrix[6], digits = 2))))+ theme(plot.title = element_text(size=10,hjust = 0.5))


ggarrange(p1, p2,p3,p4,p5,p6, ncol = 3 , nrow = 2,  common.legend = TRUE, legend="bottom")

```
Como ya se avanzó en el apartado anterior el sexo, el hecho de tener cabino o no y la clase donde se compró el billete están relacionados con la probabilidad de sobrevivir. Ser mujer, y alojarse en cabina en primera clase aumentan estas posibilidades. Por contra, ser hombre, estar en tercera clase y no tener cabina asignada la disminuyen. Aunque en menor medida el  número de familiares, el sitio de embarque y la edad tambien presentan una dependencia con la probabilidad de sobrevivir aunque más debil. Un número de familiares entre 1 y 3 aumentan la posbilidad de supervivencia, disminuyendo para familias mas grandes y en el caso que se viaje solo. El hecho de ser niño tambien aumentan la probilidad de supervivencia, así como el sitio donde se embarcó, siendo Cherbourg ("C") el ugar que las aumenta frente a Queenstown ("Q") y Southampton ("S").  

Se ha de comentar, que estas variables pueden tener dependencias entre, influyendo alguno de los niveles de unas en las otras. Por ello ejecutar algoritmos de clasificación ayudará a mejorar la interpretación de los resultados ya que maximizará la combinación de variables que mejoran la probabilidad de sobrevivir. 

### 5.2. Representación del árbol de decisión

La aplicación de un árbol de decisión aporta una buena descripción de los datos debido a sus características. Cuando se analiza un árbol de decisión que clasifica los registros, en nuestro caso por supervivencia o no, nos ayuda a comprender qué peso y cómo se utilizan las variables para comprender la supervivencia o no de los pasajeros. 

A continuación, se muestra el árbol de decisión.

```{r}
arbol_1
```

Se realiza un gráfico del árbol de decisión para visualizar como las variables explican la supervivencia o no.

```{r}
rpart.plot(arbol_1, type = 2)
```

Como se puede observar en el árbol generado, la primera variable a partir del cual se realiza una buena discriminación es **Sex**. Dependiendo de cada sexo, se utilizan otras variables para seleccionar si la persona sobrevive o no. Todas las variables se han utilizado para tomar la decisión de la supervivencia o no de los pasajeros. Algo curisoso que se ha detectado tras este análisis es que si se es mujer y de la clase 1 o 2 el árbol de decisión considera que se sobrevive.

### 5.3. Representación del Random Forest

El algoritmo de random forest genera muchos árboles de decisión de forma aleatoria. Su interpretación es más complicada que el árbol de decisión, pero nos aporta información. Por un lado, refuerza el árbol de decisión en el caso de que este reduzca el porcentaje de aciertos (como es el caso), esto puede ser a que el algoritmo de random forest a veces sobreajusta ciertos grupos de datos.

```{r}
plot_multi_way_importance(rf, size_measure = "no_of_nodes")
```

Con el anterior gráfico podemos ver el núemro de veces que cada variable ha sido considerada la raíz del árbol. Por lo tanto, las variables más utilizadas cómo raíz son aquellas más explicativas o discrimitatorias. Como se puede observar, la variable **Sex** es la más utilizada y coincide con el árbol de decisión. Las variable **Fare** también describe muy bien la supervivenvia o no de los pasajeros. En cambio, la variable **Age** es muy poco descriptiva para la supervivencia en comparación a las demás. Esto puede ser debido a que la mayoría de los registros son adultos o no identificados donde hemos visto que esta variable no tenía mucho peso, en cambio, era bastante descriptiva para los menores lo que refuerza el conocimiento de los datos.
